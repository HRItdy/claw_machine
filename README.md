# claw_machine

## This repo is a project to control the UR5 robot to grasp object. 
**Model used:** 
GPT, GroundingDINO, Segment-Anything

**Features:** 
1. The **GroundingDINO** and **Segment-Anything** are integrated to detect the object.
2. The functions are wrapped as individual services. 

**TODO:**
- Enhance the groundingdino with GPT-4.
- Now the detection is only executed once. If want to track the object, can use XMEM or recent SAM-v2.
- Write the launch to run the nodes simultaneously.
- Form a document.
- Use the graspposMap to do the grasp.


## Sturcture:

**LargestCluster:** A nodelet to select the largest cluster from the clusters generated by EuclideanCluster nodelet.

**PickUp:** The main package including detection, depth and manipulation services.
- pc_calibration.py: The script to map 2D image coordinates to 3D position on tabletop (essentially a plane-to-plane homography projection).
- models.py: Logic to load GroundingDINO and Segment-Anything. **TODO:** change the path to relative path.
- claw_detect.py: Receive the instruction, detect the target and feedback the mask.
- claw_depth.py: Receive the bottom point of the mask, project it to the tabletop coordinate, 
- ur_executor.py: Connect to the robot and initialize the actionlib.
- claw_pickup.py: Initialize the pickup service.
- **external**: Folder containing the call_service script can be called in other workpackages (called in PromptChat project).


## How to use:
### Run sys_lux.launch
Run the remote ROS node and publish multiple data to topics.
### Run pc_calibration.py
 - For image point input, run `python pc_calibration.py`, select four points in counterclockwise order. The order of the points is indicated by number. Remember to input the pointcloud coordinates accordingly.
 - For point cloud points input, run `rostopic echo /clicked_point`, select `Publish point` in rviz, click the bottom of each ball, the coordinates will be published into `/clicked_point` topic. Input them into the terminal.
### Run claw_detection.py and call_detect_service.py

### Run pc_segment.py
The center point is published to `..... ` TODO: Add the pipeline diagram and the architecture of the topics in readme.
