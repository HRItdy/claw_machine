# claw_machine

## This repo is a project to control the UR5 robot to grasp object. 
**Model used:** 
GPT, GroundingDINO, Segment-Anything

**Features:** 
1. The groundingdino and segment-anything are integrated to detect the object.
2. The detection is wrapped as one service. 
3. In this service the mask of the object is generated and published to `/mask` topic.

**TODO:**
- The projection from 2D pixel coordinates to 3D pointcloud coordinates is not accurate.
    - Use visualize maker to visualize the processed pointcloud.
    - Create a service to directly get the 3D point cloud on the remote PC.
    - Create a service to project the 2D pixel to 3D pointcloud coordinate on the remote PC.
    - Create a launch file on the local PC to call the service.
- Enhance the groundingdino with GPT-4.
- Now the detection is only executed once. If want to track the object, can use XMEM or recent SAM-v2.


## Sturcture:

**LargestCluster:** A nodelet to select the largest cluster from the clusters generated by EuclideanCluster nodelet.

**PickUp:** The main function. Now contains the detection and grasping. Overlay is to be done.

**call_service_global.py:** The client to call the detection service. Can be placed in any other ROS package or projects. But remember to place the `srv` file into the project.
